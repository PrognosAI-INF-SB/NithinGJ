{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4b88f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preprocessing FD001 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:686: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:706: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD001 CSVs saved successfully.\n",
      "FD001 LSTM sequences saved. Shape: X=(17302, 30, 21), y=(17302,)\n",
      "\n",
      "--- Preprocessing FD002 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:686: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:706: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD002 CSVs saved successfully.\n",
      "FD002 LSTM sequences saved. Shape: X=(38215, 30, 21), y=(38215,)\n",
      "\n",
      "--- Preprocessing FD003 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:686: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:706: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD003 CSVs saved successfully.\n",
      "FD003 LSTM sequences saved. Shape: X=(21278, 30, 21), y=(21278,)\n",
      "\n",
      "--- Preprocessing FD004 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:686: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\Nithin G J\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:706: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD004 CSVs saved successfully.\n",
      "FD004 LSTM sequences saved. Shape: X=(45705, 30, 21), y=(45705,)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# PrognosAI – CMAPSS Preprocessing Script\n",
    "# Generates: preprocessed CSVs + LSTM sequences (.npy)\n",
    "# Works for FD001–FD004\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "# ================== SETTINGS ==================\n",
    "DATASETS = [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]\n",
    "RAW_PATH = r\"C:\\Users\\Nithin G J\\Desktop\\PragnosAI\\archive (1)\\CMaps\"\n",
    "SAVE_PATH = r\"C:\\Users\\Nithin G J\\Desktop\\PragnosAI\\processed_data\"  # folder to save outputs\n",
    "WINDOW_SIZE = 30\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Function to create rolling sequences\n",
    "def create_sequences(df, sensor_cols, window_size):\n",
    "    sequences, rul = [], []\n",
    "    for unit in df['unit_number'].unique():\n",
    "        unit_data = df[df['unit_number']==unit].sort_values('time_in_cycles')\n",
    "        sensor_data = unit_data[sensor_cols].values\n",
    "        rul_data = unit_data['RUL'].values\n",
    "        for i in range(len(sensor_data) - window_size + 1):\n",
    "            sequences.append(sensor_data[i:i+window_size])\n",
    "            rul.append(rul_data[i+window_size-1])\n",
    "    return np.array(sequences), np.array(rul)\n",
    "\n",
    "# ================== PROCESS DATASETS ==================\n",
    "for ds in DATASETS:\n",
    "    print(f\"\\n--- Preprocessing {ds} ---\")\n",
    "    \n",
    "    try:\n",
    "        # ======= LOAD TRAIN =======\n",
    "        train_file = os.path.join(RAW_PATH, f\"train_{ds}.txt\")\n",
    "        col_names = ['unit_number', 'time_in_cycles'] + [f'operational_setting_{i}' for i in range(1, 4)] + [f'sensor_{i}' for i in range(1, 22)]\n",
    "        train = pd.read_csv(train_file, sep=' ', header=None, names=col_names, engine='python')\n",
    "        train = train.drop(columns=[c for c in train.columns if 'Unnamed' in c]).reset_index(drop=True)\n",
    "        \n",
    "        # ======= LOAD TEST =======\n",
    "        test_file = os.path.join(RAW_PATH, f\"test_{ds}.txt\")\n",
    "        test = pd.read_csv(test_file, sep=' ', header=None, names=col_names, engine='python')\n",
    "        test = test.drop(columns=[c for c in test.columns if 'Unnamed' in c]).reset_index(drop=True)\n",
    "        \n",
    "        # ======= LOAD RUL =======\n",
    "        rul_file = os.path.join(RAW_PATH, f\"RUL_{ds}.txt\")\n",
    "        rul = pd.read_csv(rul_file, header=None)\n",
    "        rul.columns = ['RUL']\n",
    "        \n",
    "        # ======= COMPUTE RUL FOR TRAIN =======\n",
    "        max_cycle = train.groupby('unit_number')['time_in_cycles'].transform('max')\n",
    "        train['RUL'] = max_cycle - train['time_in_cycles']\n",
    "        \n",
    "        # ======= NORMALIZE SENSOR COLUMNS =======\n",
    "        sensor_cols = [c for c in train.columns if 'sensor' in c]\n",
    "        scaler = MinMaxScaler()\n",
    "        train[sensor_cols] = scaler.fit_transform(train[sensor_cols])\n",
    "        test[sensor_cols] = scaler.transform(test[sensor_cols])  # use same scaler\n",
    "        \n",
    "        # ======= SAVE PROCESSED CSV =======\n",
    "        train.to_csv(os.path.join(SAVE_PATH, f\"train_{ds}_preprocessed.csv\"), index=False)\n",
    "        test.to_csv(os.path.join(SAVE_PATH, f\"test_{ds}_preprocessed.csv\"), index=False)\n",
    "        rul.to_csv(os.path.join(SAVE_PATH, f\"RUL_{ds}.csv\"), index=False)\n",
    "        print(f\"{ds} CSVs saved successfully.\")\n",
    "        \n",
    "        # ======= CREATE LSTM SEQUENCES =======\n",
    "        X, y = create_sequences(train, sensor_cols, WINDOW_SIZE)\n",
    "        np.save(os.path.join(SAVE_PATH, f\"X_{ds}.npy\"), X)\n",
    "        np.save(os.path.join(SAVE_PATH, f\"y_{ds}.npy\"), y)\n",
    "        print(f\"{ds} LSTM sequences saved. Shape: X={X.shape}, y={y.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ds}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
